yeah we gather it's difficult to raise children too oh don't even I wasn't concerned about yeah Oh place at 19 I was like like like if someone responds same ticket yes sir class all right so welcome back so so the big topic and I guess everyone's mind is that the project proposals are due Wednesday so I don't need a completely flushed out project although the more thought you put into it the better and I understand you can be having blowing a lot techniques so you don't have to prove anything spell this out and you know it can be fairly short like I think I said 100 so like 200 words right so and itch it should be too long but what I want are the teams and basically the topic and just kind of a few things that that it get mixed up with people every year is that the focus of the project cannot be on so classification right so you can't take a bunch of data and predict will they do something or will they not do something into two classes right you can use classification but that should become a black box that's not what the project is about right it could be about doing stuff the data so classification works better but then you leave that as a lots you know that part you can do so regression where you're predicting a scaler I'm predicting how much rain will it be tomorrow that's a scalar value cancel' doing that is okay under the countries in the house otherwise it's for the machine learning class and it's just out of sculpey make this arbitrator station okay so two to three hundred words or one to two hundred words on canvas by Wednesday on every partner should submit new group should submit the same summary there aren't we haven't grouped you yet for the future parts we'll put you in groups and only one person will need to submit on canvas whatever is due but now every person in the group should submit know figure out here you up later okay and unless you've gotten permission you should be groups of two or three people okay you can only do groups of one if you've got my explicit permission if you turn in something is a group of one and you haven't gotten my permission we will probably arbitrarily pair the rest of you up and you will lose some points okay so in order to get all five of the points and the proposal just follow the instructions and you'll get the points all right any any questions on the proposal general questions otherwise I'll be here after class you can come up and ask me questions about your proposal in fact that's a great idea all right one of the pink cut Wednesday we'll talk about some word embeddings and - Kelly trips of passion and so forth but we'll also have 20 minutes at the end we're gonna do an a discussion on some ethical implications of how you represent your data in particular with these these word of things and there's a paper I hope you all try and read before Wednesday who's looked at the paper already okay good good a few people it's linked off of here so if you go donate right I'm here but if you see right right there it says ethics read click on that and it will it will go to a pic okay and we'll discuss you know some of the terminology in there you will see some of these guys today some will discuss on Wednesday so you you may not have full context of everything but try and take a look at in this will help us kind of allow to have a little bit more intelligent discussion all right great okay so today we're going to talk about so about distances and so okay so you know it's kind of a I would say most data mining classes would not have a whole lecture on just just whatever this is but I feel this is really important because this is this is really one of the most important modeling choices you you you make in any sort of data else or algorithm is going to be some underlying choice of distance how do you measure and how similar or how close or how far to objects in your your dates that are to each other okay and much of this is it's like fairly arbitrary right you can choose different distances and and then run the same algorithm afterwards and the results will be different right and there's not like there's not a right distance and there's not there's not wrong okay so then the question is how do why do I choose what distance over over another distance right how do I make that decision okay and so that's what we'll try and answer in this in this lecture okay and now it will not be a complete answer at all it'll just be some guidance and then we'll see kind of some more guidance of other sorts and more advanced guides throughout the semester on them from this choice okay yeah so have the things we'll look at that that will help us make the decisions are the so the mathematical properties of these these distances so we'll talk about that so like and we'll focus on is is the distance symmetric or does it satisfy some subset of the metric Robbie's a metric is have a reasonable set of properties that you would like a a distance that another is the well let's let's use modeling characteristic but let's say the the match two the data properties okay so there there are many ways to kind of what they will focus on in this lecture a lot of lectures is the data will often be represented as a high dimensional vector okay and there are lots of ways to get high dimensional vectors but depending on which way you get it that really will often really help you tell which distance Peaks so and so how does the properties of the distance matching opera's of the data right and then the last thing is the the efficiencies so it's part of this is just computing how fast can you compute the actual distance itself but other things are tied back to other mathematical properties and if the distance is a metric in these you can apply algorithm a and if you and you know how Renee is gonna work if it's not a metric then you might not know it's gonna work so you like not one of it you might not be able to apply this algorithm anymore right it could be you can use without any sense of hashing for this distance but you can't for this so it's hard to do sort of certain certain things officially right so it's not so these are things that will kind of we'll start to see now and we'll see throughout the semester how does this particular distance tie into the efficiency of using it and and for instance the l2 distance Euclidean distance which we'll start with is kind of the one that have most algorithms kind of can work with the hell - distance right whereas you know there are a lot of algorithms like will see Lloyd's algorithms for teams clustering is specifically designed for the l2 distance you can kind of force other distances in there but you have to through a few more hoops okay so what kind of see this throughout this okay so we're gonna think of a so in order to define a in order to define a distance we're going to say it's gonna be a bivariate function deep okay so D is gonna be a function and this is a patient's gonna be it's gonna be the map from two elements of some space X right so this is some space that the data so that the data Liza right so it could be that examples would be like Rd this is the space of Euclidean D dimensional so Euclidean vectors okay but it could also be the space of all so like grass right so this is the set of all grass could be each of my data points could be a graph how do I tell the distance between two graphs right it could be text right I have a bunch of text how do I tell the distance between two pieces of text right there are lots of this is what the space is okay so that's what this notation means and that means this is the domain of the function is axis the space X cross the space X and it goes to a range and the range will always be so Euclidean and in fact for almost I think every distance we talk about is going to be restricted to be larger than zero so often we'll put this this little part down here it means it's larger than zero and in general this is the range the aqueduct okay so we're going to need some function which is like this similarity function we talking about takes two inputs from some from the same space and compares them and the more similar they are this distance will be smaller in general okay so now so who has heard of this notion of a metric that's a who's never not where this term before and who didn't raise their hand and who's building I think I got about 80% of class with those four questions little disappointing under dissipation keep moving okay so a metric there's kind of this property of a distance that we would like it to have so each is gonna have four properties are usually written as three different things but four properties and each of these should kind of try to make sense okay so the first one is that if I have this function between any two data points it should be greater equal than zero right that's the same condition up here I said the range was Euclidean values greater equal than 0 right okay so this this seems a very it seems very intuitive the next property which often comes comes with it but this is it's there's many cases where m1 is true but m2 is not where we're gonna say that a and B are going to be equal to zero if and only if a is equal to B okay so that means that that you want them to be smaller the more similar they are and two objects their distances only equal to zero if they're identical and if they are identical they have to be equal to the distance has to equal to zero okay so this again seems very intuitive we'll see any distance a very popular distance and later this lecture that this property does apples right and we'll see if there's a class of things where this property does not hold but you you kind of map it into the space where it does hold but it just but it's this is kind of a modeling step and if this doesn't hold this is kind of maybe a weakness in the model right so this is a density okay m3 is that D of a B is equal to D of B a so so symmetry right so the distance between a and B is the same as from stainless from PA right so this again kind of kind of makes sense right it doesn't matter from which way I I you know from two objects how I put them the order I put them in that that should affect the distance now again this is how it's true in a lot of reasonable distances if I look at if I measured the distance between my my work and my home in terms of the amount of time it takes me to get home right over the pork from home to work or from work to home you know it's or even even the distance I have to travel this is different right because making left turns is harder than making than making right turns right in in England that's backwards right but in here it's easier to make the right turn than making a left turn right so there are a lot of reasonable scenarios where the right modeling choice these are not equal to each other right if I'm modeling distances then these are not equal to each other and so sometimes it kind of matters to take this into account there was a study that came out I think it was like four five years ago where I think it was a UPS decided to look at the difference between left and right-hand turns and planning the routes of their drivers and they found that this is saved like five to six five to ten percent time off of the routes that they incorporated this into their planet right so now it wasn't a metric distance anymore so there are certain things they have to be more careful about right but it was a better at modeling than what the situation was by doing this yeah so I thought these were like different metrics well it said that wasn't the metric yeah so a metric is a distance where all of these holes there's there's one morning so I will and then there'll be some algorithms that say if the distance is a metric I can apply this algorithm and I know it's going to run this faster I know it's going to give me an answer that's going to be kind of this accurate or if it's not a metric I'm not sure which is right so if I apply the key Center standard case under clustering algorithm on this distance that were where it's not symmetric here because I took kind of left and right hand turns into account then I wouldn't guarantee to get a to approximation where it is symmetric I do guarantee because right so I so there there are certain things we'll see that that you know kind of having a metric means things just automatically work right and there's a lot of algorithms that are just designed a souvenir ik and then the source but again there's this modeling trade off okay and then the fourth one is the triangle inequality so that means that the distance between a and B is never more than that if I do the distance from a to some C plus the distance from C to B so this is the triangle inequality right and so the idea is that if I have a and I have B and have a point C if I look at this distance here it's never going to be faster to go up to C and then from C down to be a there are some distances which are defined over like shortest paths so like the distance from A to B is not just as it's not the straight line but it's the shortest possible way I can get there so if I could get there through C faster than that would be the notion of distance right then I defined the straight-line distance this is not always always master right so this so one at least in the northern part of Asia kind of you'll see you're kind of the flight paths will be drawn on like a map and it will look kind of curvy right like it looks it looks like it goes towards the North Pole and then comes back down because on the map distance kind of it's not the straight path on the flattened map because it's shorter to go over the top of the globe right and so so if you want to if you flattened the map first and then use the acquittee and straight line distance this would not sass with the triangle it probably would if you kind of had to do a layover in Iceland or something but especially if there was a volcano erupting but if you didn't have to late overs ignored that part of it then it might actually be faster to kind of go over there okay and there are other cases where they're very reasonable I mean this seems like a very natural thing to one you would define the distance so shortcuts don't there aren't any kind of shortcuts that help but there's some kind of there's very natural distance we'll talk about later on so the KL divergence which is a distance between different distributions and this is not satisfy the triangle default it's about information loss and kind of its how do you model how much information you need to transfer from this distribution to this one and that's not a symmetric property right so it might be easier to describe this distribution starting from here and then vice versa okay so this is not this is not always hold from all good modeling choices again okay but for many many distances that we would like to work with satisfies all four of these properties and that makes the distance what's called a metric okay and typically if you have the choice between two distances and you think that they represent the underlying data what's going on just as well you'd probably favor it being a metric over it not being a metrics just kind of intuitively make sense so this is our first kind of guide or answering towards this question of what should a distance be but you'll see there are also lots of metrics well we'll talk about one I also mentioned there's a bit of nomenclature here a something called a is a pseudo metric is one that satisfies m1 m3 and m4 but not necessarily m2 will see that cosine distance will count as as a pseudo metric I'm saying something right now called the freshy distance between curves it's so it's also a pseudo metric and then there's another one named called a a quasi metric which satisfies M 1 M 2 and M 4 but not M 3 so it doesn't have the property of symmetry so I don't think we'll talk about specifically any any quasi metrics today because the KL divergence also doesn't satisfy either of these but there are plenty of these these quasi metrics which are which are useful in violet as well okay so you don't necessarily need to have all these properties and for instance there are some algorithms or analysis that works say if it's a pseudo metric or if it's a quasi metrics you don't need all the copies in some cases so just because you lost cemetry not all hope is lost and in running operators ok let's start ok so the largest kind of pride them we're going to talk now about when the when the data is in Rd so that means a lot to data points we'll talk about a one and I guess I'm using D in two different ways here so let me start let me I'll start specifying more clearly the D I used for a distance and I'll try and use an uppercase D I guess in the in the notes I use kind of a fancier font for D but I can't really do that okay so D for now is representing the dimension and and I have another data point b1 b2 up to be deep okay and so now the first class of distances we'll talk about are these LP so distances okay and so generically this will be defined DP between two vectors a and B and we'll authorize a shorthand P might be P because in general these would be norms between the vectors so I can do a subtraction between the vectors and then I take a special sort of norm and so this is equal to the sum of I equal 1 to D of AI minus bi I take the absolute value of this then I take it to the power P and then I take this all to the including everything inside the sums of the power 1 over P ok so taking something to the power of 1 over P looks looks a little bit confusing we'll see for the in the case of when the p value is equal to 1 or 2 this kind of is is something nice right when if I take say to the 1/2 power to square root right if I think power 1 1 / 1 it doesn't do anything the reason for this is that it preserves the preserves the unit's I want to take this inner parts of the power P and this is what distinguishes these but then if I am i measuring in feet it goes 2 feet squared right I don't want to measure a distance in feet squared so I take the the one of repeats root and then I get rid of that squared again the result is back to the same measure of feet okay so that's kind intuitively why happy in one of our P it makes the unit's kind of work out okay okay and so for this is for all values for for all values P in the range of 1 to infinity up to infinity not including infinity then this is going to be a so this then this distance is going to be a metric yes yeah yeah so it's a real value I have people longer to find this room for things other than a real about I think if they do it's very unusual I don't know if you can make it a not real value but yeah so it's a real value between 1 and now you can define it for something less than 1 ohm as well and I'll mention this but it is it's not going be enough okay just to kind of quickly see this it's going to be symmetric because I'm taking the absolute value the difference of every coordinates right so it's I can switch those around and that internal value doesn't change there it's only going to be zero if they're vectors are exactly the same otherwise I'm going to sum over some terms which are going to be and if any one was different that's gonna be greater than one yes P is going to be a value as it so think of what we're gonna look at specifically kind of we're gonna consider cases P equals two is the most common one we'll talk about what infinity means and what zero means and kind of some stuff we'll look at what happens in between this is kind of a way to think about it but for now you can think of it as two okay so think of the value of P is two for now and I'll will I'll spend a whole slide out of people's to write and yeah so the and the triangle inequality will hold for in these values between the people's 1 and infinity okay that's a little harder harder to show in general but oh just just leave it there okay so let's look at particular the let's look at the l2 distance I guess so this is going to be d2 between a and B and so in general we'll just you know why right this norm the default is that it has a two so I'll just leave off the subscript two here that's not that's intentional and then this is going to look a little bit simpler right AI minus bi squared square root okay I don't need to take the absolute value because squaring it all these makes it positive right and and so it's just the sum of all the terms squared + / the square root okay and so if I have to to theater points here a and and B and think of there's some background there some some taxes this could be you know high-dimensional then the that this l2 distance is the length of the straight line in between okay so it's it's the length this is it is equal to the length of the straight like okay and so this is also known as the Euclidean distance and so this is by the most common distance that that people use for measuring stuff it's kind of a default if you know nothing else about what to do just used use the l2 distance so suppose it's example 2 minus 2 minus 1 1 right so right the l3 distance I'm going to look at the difference here 3 to the power 3 the absolute value of 3 to the power 3 and this is going to be the distance Suite 3 to the power 3 and then I'm going to take this all to the 1/3 this is going to be 27 plus 27 to the power one-third this is gonna be greater than 0 yeah right I look at the difference between these and I take the absolute value and then I take it to the piece the third power ok so so this quantity over here somehow okay this quantity inside for each of the dimensions is always positive yeah ok ok I want to write one more up here so the the l1 distance okay this would be D 1 so this will be the sum equals I equals 1 to D of AI minus VI absolute value I take it to the once power it doesn't do anything I take it to the 1 over 1 power but do anything I'm just adding up all of the differences incorporates the absolute deities differences okay and so this is known as the also being the the Manhattan distance because it's kind of thinking of it Manhattan is laid out so like a grid it's like the the number of blocks I have to go to get between one points and another pointless city now actually if you've been to Manhattan that's got all these weird kind of cross streets running through it and so forth and I like actually it's the Salt Lake City this is instead we have we've a much better grid than they doing that so I think it's much more clear about getting between different streets yeah and there's a nice origin right at the temple everything yes Oh we'll see that the L Infiniti will have a nice interpretation and sometimes you don't actually the interpretation is not so much that is that what matters I'll show a picture in a slide or two and you'll see these mathematical properties of them and there's some nice mathematical properties of what's called the l1 minus two distance in that it kind of has used a lot it's kind of a newer idea of how to regularize stuff in machine learning and it's kind of a kind of a combination of the l1 and l2 now there's not really good intuitive meaning but it has this nice shape that ends up coming out of it and their reasons there are reasons why that works out well that we'll touch on later on this semester right so it's a minus B right so was the question it's obvious gonna be it's all gonna be symmetric where it's a pseudo metric yeah yeah so well we'll get to this a bit later all the lp distances in this range are are going to be metrics we'll see the cosine distance in 1050 minutes and you'll see a good example of pseudo metric yeah so just hold on a bit for that okay so before kind of going through oh yeah there's I mentioned for l2 distance there's you can you can create an LS H function for this so this is intelligible on the l1 distance is also MSH about okay there's a there's a way to do this where you replace the Gaussian random variables with caoxi random variables and everything works okay and there's a discussion and the previous lectures notes the very end about these Pete stable distributions and how to do this so this is also eligible so from a computational standpoint everything we've seen so far you can place l1 without you and so this is just a modeling choice in which so I want to talk about as the crow flies or with the elk to this l1 distance it looks like this right it's the I have to walk along the axes distances in order to get from one point to the other right so if I drove a taxi or a lift then I went from here to a different cross we've been up there right for if I was on some if the gridlines are actually the blocks then maybe I have to have to do this you know but the distance will be the same either either of these paths as long as they were really at the same starting an end point and they're both monotonic they're gonna be the same distance okay so so let's uh okay let's I'm going to try and draw a picture and then I'm going to show you a pretty good drawing of the picture that will look a little bit nicer but I think it's illustrate just to kind of see it happening you crop you a little bit and so what I want to do is to draw so let's say this is is the origin right so I'm going to draw this in in R 2 and R 2 and I'm gonna say that there's I'm gonna look at this is going to be the coordinate in 1 0 this is going to be 0 1 right this is going to be 0 minus 1 this is going to be minus 1 0 okay and I want to draw the I'm gonna draw the the circle right the the unit circle for several of these MLP distances right so I want to draw this circle P which is going to be the set of points in R D such that the distance from the origin to X is a for P is exactly equal to 1 okay so I'm under on all the points which are at a distance 1 from the origin right the origin yeah okay so for the L tube all right all of you know what this what I'll to circle you all know what this looks like it's a circle right right it's the circle and it's going to go through these these four cross points I have right it's these are all in the distance one so I'm trying to draw a circle here there so that's a circle I think I put that 1 1 checkmark over too far and that's why it's a little oblong that's nice right so this is the this is the l2 circle or let me call this c2 right that's the circle for the l2 distance okay what does the l1 circle look look square nut quit square and wrong also aramis right yeah so it's gonna be a tilted square right so it's gonna go through all of these points but it's it's gonna look like this instead right this the distance from here to the origin is the sum of this distance and this distance and if those are both 1/2 right and the total distance is 1 right so in this but if I look at the l2 distance to that point it's going to be less than 1 1/2 squared plus 1/2 squared is is is is going to be 1/2 yeah so oh then square root of that so 1 over square root 2 which is a little bit less than 1 yes so this is those are on the l1 circle that's gonna complete it like this okay okay so now we think of the I'm going to find the L infinity distance so now infinity just and this is another one that's going to be easy to draw now my LP distance did not technically make sense for for when I put P equals to infinity because I took something to the infinite power but we want to kind of think if I take it to the infinite power and then I take it to the one over infinite power kind of what's gonna happen is that I'm gonna do a max of our I equals 1 to D instead of a sum of the distance between AI and bi okay so this is the l infiniti distance and this is kind of the limits of what happens if I take P to P to infinity this is what the distance will look like essentially the furthest the coordinates are first the part those are going to be taken to like the millionth power and 8 something that distance is a little bit less than that one then it's also me taken to the millionth power but the small differences are going to give kind of really spread out by taking it to the millionth power and then my average DS and I take the to the power 1 over P and I squash it back down again but only the largest one is gonna remain and I take it to infinity eventually it'll look like this alright so this is going to be again this is another metric but it's it's not technically a now distance but it's going to saturate kind of all the same properties okay so what does the the the L infinity circle look like square yeah now now we're at a square it's going to look like this right so it's the it's depends whichever coordinate is the largest right here only the x-coordinate matters right here only the y-coordinate matters right and they both matter only at this special point in Clarke okay and so what's nice about this this will be see the c-more ok so what's nice about it is you can kind of see if I go for 1 to 2 to infinity these balls are getting these circles are getting nicely larger and this bowls right if I were to pick any value say c3 it's going to be somewhere sandwiched between the c2 and the seen fitted right so the seat 3 ball is going to kind of go in through here then did the see 1.5 ball it's going to go somewhere in this range here what happens if I do to see 1/2 ball if I set P equals to 1/2 yes it's certain looking like a star let's let me to try and draw this this is gonna kind of look like this it's gonna still hit these points on the axis but it's going to kind of curve inwards right and so this shape is kind of kind of a ah what what's key about this is that the l1 misses is the smallest p-value where this shape is going to be convex convex basically means if I picked if I look at inside of this so the ball so a circle is kind of just the boundary of the ball so if I look at everything inside of the ball c1 if I took any two points I draw a straight line between them it'll be contained inside of it'll stay inside the ball that's no longer true here right I can take a couple of points so I can take a point here and a point here and the distance straight line between the mobile outside of this ball right so it's no longer convex and anything where the p-value is less than 1 will not be convex and this essentially is what screws up like this it's it's metric properties okay so that l1 is is kind of is going to be the extreme location we want to use it for some some sparsity inducing regularization we'll see later on in the semester okay I want to ask you one more question here what if I drew the si0 circle what the c0 circle look like yes it's kind of like it's it's like the it's it's the limit of I keep going with the see 1/2 ball and it's gonna essentially have these like spikes out here okay so this is like the c0 you can see that that well but that's the c0 circle up there it's kind of kind of wild it's actually it's not a long hearing then it's it's like they're dashes and includes these points but but nothing else okay so yeah that's kind of weird in higher dimensions you can kind of see some some structure to it it's basically counting c0 by right back and probably can't see okay so c0 is basically counting how many so matches and it's basically it's a relative of what we want to do for or this is ll0 this is basically what we want to do for the the min hash vectors to get and it's basically related to the so the Hamming distance which in information theory is like the typical distance that's usually use where all the values are just 0 1 so you're just counting how many bits are the 0 okay so L 0 is not eligible but people figure out how to make every LP greater than 0 LS a Chabot so then what you can do is you can you can do like you can approximate L 0 with ll 0.001 and then do LSH function on that and then it works well enough so you can do you can design something which essentially gives you an LS H with a little bit more error on this now those are very inefficient essential options so technically you can do it but in practice probably not between LSH and matrix is there I have so there are four certain classes of distances I don't know if every metric you can do a little searchable but there are your bonus question on the homework for two is about set based distances like the jacquard business and I gave you I think ask you about and birth similarity the enric distance and it turns out there's it's well defined for this general class of set-based distances I talked about what values are tell us hm if I give too much away for that question it's still some work to figure it out it I think it's a hard hard one I made it easier but that's if you can look at the bonus there and so there's some understanding there it's known for like the class of LP distances which are Ellis have a teachable and so forth and for other sorts of distances people are kind of this is somewhat inactive areas there's still some things people don't know what is it what is not yeah okay good okay so let's uh yeah so let's okay so here is my picture this is what it's supposed to look like you know this is a nicely drawn picture what we just any questions on that value see it drawn percent forty and zero distance so that the problem lzo distance is also technically not defined to this LP version because taking something to the 1 over 0 power is essentially taking to the infinite power so it's it's basically the number of the distance is the number of mismatches oh so well sometimes it's one over deed has the number of its matches there they're different ways of defining ll0 business how you normalize it and so forth yeah just within that picture it kind of makes sense to draw a family but you can't really draw the l0 distance circle the same way other so kind of take that with a grain of salt distant to stop it yeah well yeah it depends on how do you how you might define it yeah it's one of these things that's not technically defined properly so you show you choose some some something to represent that that kind of data at the limit and there are there some choices you can make there okay okay now I want to show a more important picture okay this this has to do with LP distances as well like um I found this on the internet there's this apparently as far as I know this is a real sign there's a place called new Koriyama the population is 562 feet above sea level 2,100 feet established in 1851 and they've added these numbers up you know it seems like sure yeah that seems interesting and there's lots of like numerology about if you add up numbers and there are crying something's magical happens okay but like okay so the problem is people will often do this when they're using LT distances okay if you look at this LT distance there's a sum right in here and you're adding up different things so if I have a vector about someplace called you know you know calling nucleoli and I'm looking at the difference between new kanuma and Salt Lake City right that the population is different the feet above sea level is different and what it establishes different I can do the LP distance or the help to distance between these two vectors and at some point in there I'm looking the difference and then I'm taking the sum and this is nonsense okay this is nonsense okay and using LP distances that way is also nonsense okay don't do it right don't and this is often not talked so okay so people will use out the distances between vectors with different units and you should not do that okay it's a that's a that's a whore job of modeling right what's gonna happen was it this is gonna look like well with Salt Lake City okay they were established maybe roughly a hundred years apart there are feet above sea level is about 2,000 feet off right if I have Salt Lake City here right so it was at 1847 is that right 46 in one no no one knows okay let's say this about 1847 right so feet above sea level about let's say 4400 right and population it's about to 250,000 all right so if I took the differences here this is going to be about 250,000 this is about two hundred and fifty and this is about let's say a hundred and four and I and then I maybe maybe I square these or maybe I don't let's to say the hell in this sense and I add these up right everything is in the difference in population right that's these other numbers are just noise here I've lost that information right because you know me this difference is what's really meaningful between them but it's such a smaller scale that population that it's you know I've lost the information right and so what is the right thing to do here yeah okay so I can have a different distance for each unit and I can say okay instead of it's got a a distance here at this is here and business here and I can combine those together and so on yeah but all the reads to them what weights to them okay good right so I can instead I can say let's say I'm gonna take this this difference here and I'm gonna have a weight 108 - and a weight 3 here and I'm gonna wait them before I do anything right so that this is a this is essentially the right thing to do we're going to actually get some more general than just weight snacks but then I have to choose these weights around right and and this is kind of this is a hard question how do I choose these weights to define my distance instead of just saying well should I use an l1 or l2 now I have like this whole club continuous set of weights I could choose from now that's a hard Bamako I know I don't just have this binary choice of two normal things but I have this infinite choice of distances actions okay so well I'm there's this this for the literature called distance so metric so learning where you kind of figure how to learn essentially these weights something a little bit more complex and I'm gonna I'm gonna add a lecture into class roughly this that will come after we talked about SPD and PCA because some of the techniques need this I haven't had this in class before since the dominant techniques kind of just formulate something and just throw it into some some solver either a linear solver some run some great descent on it and and we don't talk about any of those tools anywhere else but I think I found some some fairly some competitive techniques that use kind of techniques on the first order that we came in this class we'll talk about this later in the semester how do we choose these weights what's interesting is how do we formulate these weights inside of the consignment distance and there's there's have a well-defined type of distance called the the Mahalo know this distance and it's precisely a distance that essentially is adding these weights but also some kind of cross terms as well and so it's define again on products but involves some matrix so I need so this requires right here we've requires a D by D matrix now okay so I'm gonna require this matrix and then my distance will be a d em between a and B and there are a few ways you can write this can use a minus B transpose times M times a minus B and then the square root so this is going to look like this is essentially in l2 distance but I'm doing some some scaling here and so I'm gonna write some special cases of this and kind of explain what's going on if M equals I the identity matrix which is 1 which is ones on the diagonal 0 off diagonal dead then then DM is is d2 right is is going to be the l2 distance right this this is basically in a product between the differences and I take the square root and that's basically the inner product with something by itself is basically as same thing as its norm and so that's that's what I'm doing inside so if I make this the simplest possible D by D matrix which is the identity matrix this is exactly the l2 distance if equals let's call this w which is weight one way to up to weight D and everything off off here is zero right then this distance is going to be equal to equals 1/2 D of weight i AI minus VI squared square root okay so if I just have if it's still a diagonal matrix matrix with weights on on the diagonal that's exactly what you were suggesting before where I just put weights on on the on the different coordinates so it's just a weighting the coordinates differently here if I just have this form of the matrix but in general I can I can put off diagonal weights here as well and this is allowing me to they kind of combine how terms interact in in certain ways okay so let me draw a picture that will help clarify what's going on here let me draw let's do a new one okay so again I'm gonna have my axes here I'll draw them a little bit more narrow okay so now I'll start with this is with the help to ball and this is with M equals the identity matrix right so that's unit ball here now let's say that I have a weight matrix which is let's say it's 2 1 right so it's I'm in r2 here right so I just have two weights I need to choose and I have one weighted by 2 and the other weighted by by buying one so the Y directions which I want the X Direction is weighted by 2 this is gonna be you know lips and it's gonna be bigger or smaller than the other yeah it's gonna look like this that's gonna be inside of here because I can only go out I can go to distance a half and it's weighted by two and it goes out over so this is with weight here if I change the 212 one half then it's going to be even expanded out this one okay so what right so this is I mean let me draw if I do this one instead if this was the red W if I do this one equals one half zero zero one that looks like this it's gonna be an ellipsis white it's a horrible lips but it's a perfect like it should be perfectly in an ellipse time okay so what if I want what can I do with a matrix with off with hot bag numbers right how could I change this what more power doesn't get how could it change the ball and these dumb bitches yeah yeah if I loud an M that where these outside elements were not zero turns out will still be no lips it'll still be centered at zero but something else will be different so yeah I can rotate essentially its encoding a rotation as well and within general M it could look like like this this could be the this is what you can do it's still centered at zero but if you know how it ellipse is defined to go into T it's got a major axis and a minor axis and these will not be aligned on the economy on the coordinate axis okay and so this means that like if I you know why this is interesting is if I have two data points a and I have you know B and I want to say which one is closer to the origin under this men one under this Mahalanobis distance with the the green one B is closer to the origin a name but under the the one this with this with this pink with the pink ellipse a is closer the words of nd probably under the AL to distance maybe they're roughly the same under the the red one I'm not sure right might be you don't want it might be about the same right but so this is what you know you change which which points are closer than other points when I do this and that's kind of the the key to choosing a distance it tells you which points are close and which ones are not close yes so he's one here to go away from you know caress I didn't get yes yeah so our beers or anything that's on this boundaries one unit away this might be less than one unit or right in under the Mahalanobis green distance here under the pink Mahalanobis distance is greater than one unit a is near I mean it's closer to the origin than inside yeah that's yeah especially thinking proposed a is close to the origin under the pink purple one B is close to the origin under the green yeah so distances so specifically would select your heart with your just going yeah Jakarta where is this only for healthy business I mean this is generally this how you talk about weights and helping distances you could probably add weights into the Jaccard distance and have probably work I think it's a I think it won't work but I'm not sure I haven't thought about this yeah it's less common to talk about than that but it's very reasonable thing to do modeling once again choosing the weights you know you'd have well I'd I'd make that decision and sometimes that's the ranking okay what else do I want to say this okay so we've got 15 minutes left I'm going to go through some other some other distances okay so as well we'll just go through these a bit more more quickly the Jaccard distance uppercase D so the distance your car between two sets a and B is just 1 minus the Jaccard similarity right and and so it turns out that that this one is also a also a metric you can think of it you know it's 1 minus a intersection B over a union B you can also write it as a symmetric difference of the size of that over a so union B so it's pretty easy to see that this one is is going to be only 0 if it is if a and B are the same that's the only way for their insect intersection to be as large as SRU and that's the only way to get this term to be 1 1 minus 1 that's the only way to give 0 and and these are symmetric because intersection and union operations are symmetric can be okay it's also a triangle of satisfies triangle inequality I think I'm going to choose not to go through that in class but there's a you know it's it's a pretty short proof that spits in the notes you can look at it it's it's understandable from principles it's about five lives but I'm just gonna I'd rather mention some other distances okay and and so a lot of the set-based distances you get you created distance and it's often a metric if you can do 1-2 Jaccard similarity and I think if this is a metric that means it's eligible I forget the exact kind of distinction between those those two things but I am pretty sure that's the case if this is a metric if you won - asset-based jacquard set base of learning and symmetric and that will give you it eligible okay so another distance I have previewed is the cosine distance and I wanted to talk about this one so this also takes in the objects in here on the space and we say this is a metric space that this is a metric but again this is is it's not going to be a metric the space is going to be equal to Rd that means again a is a is this going to be a vector and hence so it's B right so the inputs are we're going to be vectors and typically you restrict so you would often restrict that each a I is going to be greater equal than 0 that's in most data sets this is giving the case the most common way to get this is is from the bag of words approach to taking a text document right and each index tells you a different word that that has occurred how many times that word has occurred right so it could be mainly zeros right but the other ones are counts okay um this this comes up in other places where a and B are representing some discrete kind of count of what is going on of counting IP addresses that have witnessed that around right so you can imagine lots of scenarios where this sort of you would model data okay but to talk about the cosine similarity which is a popular way to use with with the bag of words right this is this is kind of very popular thing to use we we want to think of it as something that not just house we want to compare documents of different size to each other and so we want to get rid of the notion of the count so we would define the cosine distance between a and B is going to be 1 minus the inner product between a and B or the the dot product between them divided by the norm of a times norm of B and these are l2 norms of that drama no scrub subscript right it's reminder one - this dot product is AI times bi I'm summing over all any IDI terms okay okay so this is not a metric it's actually a pseudo metric and the reason for this is that I can think of having origin down here and having like having a circle of distance one and then I'm gonna have some vector a have another vector B here and essentially what I'm doing is I'm projecting these guys down towards towards the origin on to the circle okay and then the cosine distance is actually telling me in radians essentially the disc the jus dezik distance on the surface between these two values as the geodesic distance between these two these two points on this skier this high dimensional sphere onto the unit station I'm dividing what I divide the value I can think of pushing this is divisions through in the inner product right so I can write this as equal to 1 minus the inner product of a over a normalized and B over B normal so I'm basically creating create these unit vector versions of a and B right so the the norm of these vectors are one that means it's on this l2 l2 sphere and then I take the geodesic distance on the cell to escape and this is the cosine okay okay so this is clearly going to be symmetric and if a and B are equal to each other then it's then they're going to have a distance of zero but this em--to property if the distance is zero then they're equal to each other this is not why does this not yeah right so I can have another point here let's do C and it's projection is to the same spot right so so this the distance we can see is zero the cosine distance but they're not the same they're not the same vector think of taking a a document and copy and pasting the the whole document beneath itself in the fact actually this is a common thing that a lot of what they just did it at some point we'll talk about that later in the semester and their distance to each other is zero and the cosine distance because they have the same kind of word distribution right so because that's not metric you know once you've projected them onto you've got the normalized vector as though it is a metric there right if I say it's the distance between unit vectors then then it is a mentor in fact it satisfies a triangle equality any any geodesic distance where I'm measuring the length on some manifold this is the spheres of all the manifold here I'm gonna get into that but if I look at the geodesic distance which is the shortest path restricted to this manifold and look at that distance that's always satisfies triangle inequality so this ends up being this is a metric if I restrict the space to be all all of the just just unit vectors I look at restricts it to unit vectors in R T then then this is is a metric again it turns out this is this is Ellis a channel one reason that this is used in particulars is a really cool LSH function for it I basically take no random a random unit vector and I take the dot product with with the object and if it's positive I return plus 1 that's negative I return to minus 1 so my hash function is buying it that output is buying it either plus 1 or minus 1 it turns out if I look at if I then do like the Hamming distance between this between these vectors this this kind of converges again nothing but an expectation converges to the cosine distance Francis so I get this really cool LS a function so this is this LS agent so this is commonly used with with bag-of-words and there's an LSA predator and it allows you to normalize documents kind of automatic okay so I want to mention let me mention two other distances super quickly KL divergence and so there's a class of these information distances which are kind of a bit more modern take I mean they're probably older than the cosine distance but they're a more modern way to try and deal with similar data again I'm going to have these words that come from these these come from cows but then what I do is I normalize it differently this is going to be a divided by the l1 norm of a okay instead and this is gonna this is so it's gonna be on the elbow it's gonna have the property that if I look at the sum over all to D of a bar absolute values of these this is going to add up to one so this means this is equivalent to impede a a probability so distribution so this describes the probability that I get that the word that you know if I pick a random word in a document the probability that's Apple corresponds to the index in this vector that corresponds with the word right so this is now a probability vector and a common distance which is not satisfy the triangle quality is let's say and B here is it is called the if is is called the KL divergence which is equal to 1 the sum of wanted e of a I natural log a I / bi rights so this is not symmetric and is not SAS with a triangle inequality there's there's another information just since the the Hellinger distance which is is it's basically let's see if this right is I take the square root inside of here and then I there are a couple of variants of it and then I can do like an l2 version of this where I take the square root of these things inside and this is this one is symmetric and there's some information theory root students this one looks kind of like entropy and it's basically measuring the amount of information I need to describe one distribution of from the other distribution one minute left let me tell you about the Edit distance just because this may come up and this is the the distance between where a and B are two pieces of a strings of text there's a string of text and so this is basically the number of changes needed to get to a frog okay so if I go to cat this is hats this is equal to B then the Edit distance the edit is equal to - I do a c2 an H and I add right so I go cat hat tax so this is took two steps ok so this is the usually the right distance to use between two short works like if you looked in a search and you miss type something or for a spell check this is commonly busiest and so it's the right thing to add very short pieces on the strings of text it's not very useful above like 3 or 4 points it starts becoming useless we can get almost anywhere in three or four steps it's also not eligible really there's like no good no hello state or even approximation so this is basically not LSH of all and basically this is kind of a big issue if this is have the best example things are not eligible it already computed based we need like some form of dynamic programming to compute the assistance and things that tend to look like they use dynamic program are generally not holistic okay so I'll stop there and then make sure you do the reading for the ethics discussion on Wednesday and turn your proposals and come talk to me now after class other to other
